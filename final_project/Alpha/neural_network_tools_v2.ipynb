{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netork Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#NN ones\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('clean_data.csv')\n",
    "main_df.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "main_df.dropna(subset = ['runtimeMinutes'], inplace = True)\n",
    "main_df.reset_index(drop = True, inplace = True)\n",
    "main_df.fillna(value = 'Unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        primaryTitle  runtimeMinutes       genres  \\\n0                         Frivolinas            80.0       Comedy   \n1                     Kate & Leopold           118.0       Comedy   \n2           The Woman with the Knife            80.0        Drama   \n3         The Other Side of the Wind           122.0        Drama   \n4                  The Naked Monster           100.0       Comedy   \n...                              ...             ...          ...   \n114920                     Albatross            97.0  Documentary   \n114921  9/11: Escape from the Towers           120.0  Documentary   \n114922    La vida sense la Sara Amat            74.0        Drama   \n114923                    Drømmeland            72.0  Documentary   \n114924           Kuambil Lagi Hatiku           123.0        Drama   \n\n                 directors           writers  averageRating  numVotes  \n0          Arturo Carballo           Unknown            5.6        15  \n1            James Mangold     Steven Rogers            6.4     76677  \n2           Bassori Timite    Bassori Timite            6.5        11  \n3             Orson Welles      Orson Welles            6.8      5469  \n4               Ted Newsom        Ted Newsom            5.5       250  \n...                    ...               ...            ...       ...  \n114920        Chris Jordan      Chris Jordan            8.2        23  \n114921       Grace Chapman           Unknown            8.4        37  \n114922           Laura Jou        Coral Cruz            6.7        77  \n114923  Joost van der Wiel           Unknown            6.6        36  \n114924   Azhar Kinoi Lubis  Arief Ash Siddiq            8.4         5  \n\n[114925 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primaryTitle</th>\n      <th>runtimeMinutes</th>\n      <th>genres</th>\n      <th>directors</th>\n      <th>writers</th>\n      <th>averageRating</th>\n      <th>numVotes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Frivolinas</td>\n      <td>80.0</td>\n      <td>Comedy</td>\n      <td>Arturo Carballo</td>\n      <td>Unknown</td>\n      <td>5.6</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kate &amp; Leopold</td>\n      <td>118.0</td>\n      <td>Comedy</td>\n      <td>James Mangold</td>\n      <td>Steven Rogers</td>\n      <td>6.4</td>\n      <td>76677</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Woman with the Knife</td>\n      <td>80.0</td>\n      <td>Drama</td>\n      <td>Bassori Timite</td>\n      <td>Bassori Timite</td>\n      <td>6.5</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Other Side of the Wind</td>\n      <td>122.0</td>\n      <td>Drama</td>\n      <td>Orson Welles</td>\n      <td>Orson Welles</td>\n      <td>6.8</td>\n      <td>5469</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Naked Monster</td>\n      <td>100.0</td>\n      <td>Comedy</td>\n      <td>Ted Newsom</td>\n      <td>Ted Newsom</td>\n      <td>5.5</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>114920</th>\n      <td>Albatross</td>\n      <td>97.0</td>\n      <td>Documentary</td>\n      <td>Chris Jordan</td>\n      <td>Chris Jordan</td>\n      <td>8.2</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>114921</th>\n      <td>9/11: Escape from the Towers</td>\n      <td>120.0</td>\n      <td>Documentary</td>\n      <td>Grace Chapman</td>\n      <td>Unknown</td>\n      <td>8.4</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>114922</th>\n      <td>La vida sense la Sara Amat</td>\n      <td>74.0</td>\n      <td>Drama</td>\n      <td>Laura Jou</td>\n      <td>Coral Cruz</td>\n      <td>6.7</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>114923</th>\n      <td>Drømmeland</td>\n      <td>72.0</td>\n      <td>Documentary</td>\n      <td>Joost van der Wiel</td>\n      <td>Unknown</td>\n      <td>6.6</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>114924</th>\n      <td>Kuambil Lagi Hatiku</td>\n      <td>123.0</td>\n      <td>Drama</td>\n      <td>Azhar Kinoi Lubis</td>\n      <td>Arief Ash Siddiq</td>\n      <td>8.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>114925 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count     114925.000000\nmean        4785.097350\nstd        37203.975544\nmin            5.000000\n25%           17.000000\n50%           71.000000\n75%          405.000000\nmax      2195241.000000\nName: numVotes, dtype: object"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "main_df.numVotes.describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting adequate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's gucci!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the number of ratings is skewed towards a lower amount of votes. These ratings with lower amount of votes might not be good for the analysis since most likely is not enough to be a good assesment of the ratings. I will make a cutoff at the 50th percentile in order to eliminate that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "count      57712.000000\nmean        9505.572654\nstd        52072.703031\nmin           71.000000\n25%          159.000000\n50%          402.000000\n75%         1551.000000\nmax      2195241.000000\nName: numVotes, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "cutoff_50th_df = main_df[main_df['numVotes'] >= 71].reset_index(drop = True)\n",
    "cutoff_50th_df.numVotes.describe().apply(lambda x: format(x, 'f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                     primaryTitle  runtimeMinutes  genres          directors  \\\n0                  Kate & Leopold           118.0  Comedy      James Mangold   \n1      The Other Side of the Wind           122.0   Drama       Orson Welles   \n2               The Naked Monster           100.0  Comedy         Ted Newsom   \n3            Crime and Punishment           126.0   Drama      Menahem Golan   \n4        The Wandering Soap Opera            80.0  Comedy  Valeria Sarmiento   \n...                           ...             ...     ...                ...   \n57707                   Pengalila           111.0   Drama      T.V. Chandran   \n57708                   Manoharam           122.0  Comedy        Anvar Sadik   \n57709   Padmavyuhathile Abhimanyu           130.0   Drama    Vineesh Aaradya   \n57710           Sokagin Çocuklari            98.0   Drama  Ahmet Faik Akinci   \n57711  La vida sense la Sara Amat            74.0   Drama          Laura Jou   \n\n                 writers  averageRating  numVotes  \n0          Steven Rogers            6.4     76677  \n1           Orson Welles            6.8      5469  \n2             Ted Newsom            5.5       250  \n3      Fyodor Dostoevsky            5.8       618  \n4                Pía Rey            6.7       227  \n...                  ...            ...       ...  \n57707      T.V. Chandran            8.8       550  \n57708            Unknown            6.9       318  \n57709    Vineesh Aaradya            8.0       263  \n57710  Ahmet Faik Akinci            6.2       196  \n57711         Coral Cruz            6.7        77  \n\n[57712 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primaryTitle</th>\n      <th>runtimeMinutes</th>\n      <th>genres</th>\n      <th>directors</th>\n      <th>writers</th>\n      <th>averageRating</th>\n      <th>numVotes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kate &amp; Leopold</td>\n      <td>118.0</td>\n      <td>Comedy</td>\n      <td>James Mangold</td>\n      <td>Steven Rogers</td>\n      <td>6.4</td>\n      <td>76677</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Other Side of the Wind</td>\n      <td>122.0</td>\n      <td>Drama</td>\n      <td>Orson Welles</td>\n      <td>Orson Welles</td>\n      <td>6.8</td>\n      <td>5469</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Naked Monster</td>\n      <td>100.0</td>\n      <td>Comedy</td>\n      <td>Ted Newsom</td>\n      <td>Ted Newsom</td>\n      <td>5.5</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Crime and Punishment</td>\n      <td>126.0</td>\n      <td>Drama</td>\n      <td>Menahem Golan</td>\n      <td>Fyodor Dostoevsky</td>\n      <td>5.8</td>\n      <td>618</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Wandering Soap Opera</td>\n      <td>80.0</td>\n      <td>Comedy</td>\n      <td>Valeria Sarmiento</td>\n      <td>Pía Rey</td>\n      <td>6.7</td>\n      <td>227</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57707</th>\n      <td>Pengalila</td>\n      <td>111.0</td>\n      <td>Drama</td>\n      <td>T.V. Chandran</td>\n      <td>T.V. Chandran</td>\n      <td>8.8</td>\n      <td>550</td>\n    </tr>\n    <tr>\n      <th>57708</th>\n      <td>Manoharam</td>\n      <td>122.0</td>\n      <td>Comedy</td>\n      <td>Anvar Sadik</td>\n      <td>Unknown</td>\n      <td>6.9</td>\n      <td>318</td>\n    </tr>\n    <tr>\n      <th>57709</th>\n      <td>Padmavyuhathile Abhimanyu</td>\n      <td>130.0</td>\n      <td>Drama</td>\n      <td>Vineesh Aaradya</td>\n      <td>Vineesh Aaradya</td>\n      <td>8.0</td>\n      <td>263</td>\n    </tr>\n    <tr>\n      <th>57710</th>\n      <td>Sokagin Çocuklari</td>\n      <td>98.0</td>\n      <td>Drama</td>\n      <td>Ahmet Faik Akinci</td>\n      <td>Ahmet Faik Akinci</td>\n      <td>6.2</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>57711</th>\n      <td>La vida sense la Sara Amat</td>\n      <td>74.0</td>\n      <td>Drama</td>\n      <td>Laura Jou</td>\n      <td>Coral Cruz</td>\n      <td>6.7</td>\n      <td>77</td>\n    </tr>\n  </tbody>\n</table>\n<p>57712 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "cutoff_50th_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_gen = LabelEncoder()\n",
    "le_dir = LabelEncoder()\n",
    "le_wri = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfle = cutoff_50th_df\n",
    "dfle.genres = le_gen.fit_transform(dfle.genres)\n",
    "dfle.directors = le_dir.fit_transform(dfle.directors)\n",
    "dfle.writers = le_wri.fit_transform(dfle.writers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1.1800e+02, 5.0000e+00, 1.2161e+04, 3.0473e+04],\n       [1.2200e+02, 8.0000e+00, 2.1852e+04, 2.4317e+04],\n       [1.0000e+02, 5.0000e+00, 2.8227e+04, 3.1247e+04],\n       ...,\n       [1.3000e+02, 8.0000e+00, 2.9860e+04, 3.2950e+04],\n       [9.8000e+01, 8.0000e+00, 5.0600e+02, 5.4200e+02],\n       [7.4000e+01, 8.0000e+00, 1.6714e+04, 6.2650e+03]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X = dfle[['runtimeMinutes', 'genres', 'directors', 'writers']].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0        6.4\n1        6.8\n2        5.5\n3        5.8\n4        6.7\n        ... \n57707    8.8\n57708    6.9\n57709    8.0\n57710    6.2\n57711    6.7\nName: averageRating, Length: 57712, dtype: float64"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y = dfle.averageRating\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
    }
   ],
   "source": [
    "X = ohe.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(57712, 65567)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.10,\n",
    "    random_state=13\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = tf.keras.utils.normalize(train_X, axis = 1)\n",
    "test_X = tf.keras.utils.normalize(test_X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       runtimeMinutes  genres_codes  directors_codes  writers_codes\n15942        0.006420      0.000357         0.701650       0.712493\n23500        0.004085      0.000403         0.666934       0.745106\n27191        0.023377      0.001670         0.674584       0.737826\n853          0.008080      0.001347         0.671027       0.741387\n52292        0.005190      0.000807         0.518164       0.855265\n...               ...           ...              ...            ...\n33634        0.003751      0.000556         0.669574       0.742736\n56848        0.006045      0.000285         0.056916       0.998361\n32842        0.003153      0.000166         0.668791       0.743444\n47280        0.004535      0.000267         0.666460       0.745527\n33106        0.002324      0.000000         0.471251       0.881996\n\n[51940 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>runtimeMinutes</th>\n      <th>genres_codes</th>\n      <th>directors_codes</th>\n      <th>writers_codes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15942</th>\n      <td>0.006420</td>\n      <td>0.000357</td>\n      <td>0.701650</td>\n      <td>0.712493</td>\n    </tr>\n    <tr>\n      <th>23500</th>\n      <td>0.004085</td>\n      <td>0.000403</td>\n      <td>0.666934</td>\n      <td>0.745106</td>\n    </tr>\n    <tr>\n      <th>27191</th>\n      <td>0.023377</td>\n      <td>0.001670</td>\n      <td>0.674584</td>\n      <td>0.737826</td>\n    </tr>\n    <tr>\n      <th>853</th>\n      <td>0.008080</td>\n      <td>0.001347</td>\n      <td>0.671027</td>\n      <td>0.741387</td>\n    </tr>\n    <tr>\n      <th>52292</th>\n      <td>0.005190</td>\n      <td>0.000807</td>\n      <td>0.518164</td>\n      <td>0.855265</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33634</th>\n      <td>0.003751</td>\n      <td>0.000556</td>\n      <td>0.669574</td>\n      <td>0.742736</td>\n    </tr>\n    <tr>\n      <th>56848</th>\n      <td>0.006045</td>\n      <td>0.000285</td>\n      <td>0.056916</td>\n      <td>0.998361</td>\n    </tr>\n    <tr>\n      <th>32842</th>\n      <td>0.003153</td>\n      <td>0.000166</td>\n      <td>0.668791</td>\n      <td>0.743444</td>\n    </tr>\n    <tr>\n      <th>47280</th>\n      <td>0.004535</td>\n      <td>0.000267</td>\n      <td>0.666460</td>\n      <td>0.745527</td>\n    </tr>\n    <tr>\n      <th>33106</th>\n      <td>0.002324</td>\n      <td>0.000000</td>\n      <td>0.471251</td>\n      <td>0.881996</td>\n    </tr>\n  </tbody>\n</table>\n<p>51940 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MODEL\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# MODEL'S LAYERS\n",
    "\n",
    "model.add(tf.keras.layers.Flatten()) #input layer\n",
    "\n",
    "model.add(tf.keras.layers.Dense(  #Dense hidden layer\n",
    "    100, # Number of nodes\n",
    "    activation = tf.nn.relu \n",
    "))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(  #Dense hidden layer\n",
    "    100, # Number of nodes\n",
    "    activation = tf.nn.relu \n",
    "))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(  #Output layer\n",
    "    10, # Number of nodes\n",
    "    activation = tf.nn.softmax  \n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crating compiler that will also give loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 51940 samples\nEpoch 1/15\n51940/51940 [==============================] - 4s 84us/sample - loss: 104.8716 - accuracy: 0.0209\nEpoch 2/15\n51940/51940 [==============================] - 4s 71us/sample - loss: 50.2305 - accuracy: 0.0201\nEpoch 3/15\n51940/51940 [==============================] - 4s 72us/sample - loss: 32.6192 - accuracy: 0.0198\nEpoch 4/15\n51940/51940 [==============================] - 4s 70us/sample - loss: 22.4274 - accuracy: 0.0201\nEpoch 5/15\n51940/51940 [==============================] - 4s 76us/sample - loss: 14.1485 - accuracy: 0.0207\nEpoch 6/15\n51940/51940 [==============================] - 5s 87us/sample - loss: 6.6771 - accuracy: 0.0196\nEpoch 7/15\n49952/51940 [===========================>..] - ETA: 0s - loss: 1.8141 - accuracy: 0.0248"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-8d00bfe06a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2661\u001b[0m           *args, **kwargs)\n\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_cache_key\u001b[0;34m(self, args, kwargs, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m   2499\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2500\u001b[0m       input_signature = pywrap_tensorflow.TFE_Py_EncodeArg(\n\u001b[0;32m-> 2501\u001b[0;31m           inputs, include_tensor_ranks_only)\n\u001b[0m\u001b[1;32m   2502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_X.values, train_y.values, epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5772/5772 [==============================] - 0s 77us/sample - loss: 1.7063 - accuracy: 0.0305\nLoss: 1.7062689866444674\nAccuracy: 0.030492030084133148\n"
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(test_X.values, test_y.values)\n",
    "print(f\"Loss: {val_loss}\")\n",
    "print(f\"Accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit7ce9bcd6e9604f49a75ac00b61501ba1",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}